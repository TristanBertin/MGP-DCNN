import h5py
import numpy as np

def save_mean_covar_as_h5_file(mean_array, covar_matrix_array):
    '''
    :param mean_array: mean of the GP posterior
    :param covar_matrix_array: covariance matrux of the GP
    :return: the name of the file.h5 that contains those two saved arrays
    '''

    (nb_individuals, nb_time_steps, nb_tasks) = mean_array.shape
    h5_dataset = h5py.File('output_MGP/Output_MGP_%dIndividuals_%dTime_%dTasks' % (nb_individuals, nb_time_steps, nb_tasks), 'w')
    h5_dataset.create_dataset('mean_array', data=mean_array)
    h5_dataset.create_dataset('covar_matrix_array', data=covar_matrix_array)
    h5_dataset.close()
    print('\n H5 SAVED')
    return str('Output_MGP_%dIndividuals_%dTime_%dTasks' % (nb_individuals, nb_time_steps, nb_tasks))


def generate_samples_single_id(gp_mean, gp_covar_matrix, num_samples):
    '''
    :param gp_out_mean: mean of the posterior over time and tasks for a single individual
    :param covar_matrix: covariance matrix of the GP over time and tasks for a single individual
    :param num_samples; the amount of samples per individual we want to generate
    :return: the multiples samples drawn from the posteriors distribution in an array of shape [num_samples, time_steps*num_tasks]

    BE CAREFUL : THE OUTPUT IS IN THE FORM OF [[time_1_task_1, time_1_task_2, ..., time_2,task_1, time_2_task_2, ...] * num_samples]
    '''

    gp_mean = np.tile(gp_mean.reshape(-1, 1), (1,num_samples))
    len_covar = gp_covar_matrix.shape[0]
    cholesky_matrix = np.linalg.cholesky(gp_covar_matrix + 8e-4*np.eye(len_covar))  #we add this quantity to be sure that we have a positive semi definite matrix
    posterior_samples = gp_mean + np.dot(cholesky_matrix, np.random.normal(size=(len_covar, num_samples)))
    return posterior_samples


def reorganize_samples_single_id(samples_array, nb_tasks):
    '''
    :param samples_array: array generated by the generate_samples_single_id() function
    BE CAREFUL INPUT TYPE [[time_1_task_1_sample_1, time_1_task_1_sample_2], [time_1_task_2_sample_1, time_1_task_2_sample_2],
                                                 [time_2,task_1_sample_1, time_2_task_1_sample_2], ....]
    :param nb_tasks = number of samples per individual
    return : the samples array but yet of shape [number of samples, number of time_steps, number of hormones]

    '''

    assert(samples_array.shape[0]%nb_tasks == 0)

    if (samples_array.shape[0]%nb_tasks != 0):
        raise ValueError('Invalid input shape')

    out = samples_array.reshape(samples_array.shape[0]//nb_tasks, nb_tasks, samples_array.shape[-1])
    out = np.swapaxes(out, 0, -1)
    out = np.swapaxes(out, 1, -1)
    return out


def generate_posterior_samples(h5_name, nb_samples_per_id):
    '''
    :param h5_data_path: take as input a h5 file with many datasets inside( y_data, y_mean, y_covar_1, y_covar_2, y_std, x_train, filters)
     = results of the MGP on all the women
    '''

    print('\n ---- GENERATE MULTIPLE SAMPLES FROM POSTERIOR DISTRIBUTION ----\n')

    with h5py.File('output_MGP/'+h5_name, 'r') as data:
        mean = data['mean_array'][:]
        covar_matrix = data['covar_matrix_array'][:]

    output = np.empty(shape=(mean.shape[0], nb_samples_per_id) + (mean.shape[1:]))
    (nb_individuals, nb_time_steps, nb_tasks) = mean.shape

    for i in range(nb_individuals):
        print('Individual %d/%d'%(i+1,nb_individuals))
        samples = generate_samples_single_id(mean[i], covar_matrix[i], nb_samples_per_id)
        samples = reorganize_samples_single_id(samples, nb_tasks=nb_tasks)
        output[i] = samples

    print(output.shape)
    return output



